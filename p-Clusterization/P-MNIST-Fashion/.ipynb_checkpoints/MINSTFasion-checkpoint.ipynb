{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63ef48952324>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHBox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVBox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStopWords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mstop_words_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"Preprocessing/Stop-words.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStopWords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Preprocessing'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.word2vec import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, homogeneity_completeness_v_measure, silhouette_score, silhouette_samples\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from IPython.html import widgets \n",
    "from IPython.display import display, clear_output, HTML\n",
    "from ipywidgets import HBox, VBox, Layout, Output\n",
    "\n",
    "from Preprocessing.text import Text, StopWords\n",
    "stop_words_file = r\"Preprocessing/Stop-words.txt\"\n",
    "stop_words = StopWords(stop_words_file)\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import tabulate\n",
    "\n",
    "from Configs.MNIST_Fashion.configs import DATA_DIR, LOG_DIR\n",
    "from Configs.MNIST_Fashion import mnist_reader\n",
    "from Configs.MNIST_Fashion.helper import get_sprite_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DATA_DIR)\n",
    "print(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    X, Y = mnist_reader.load_mnist(path=DATA_DIR, kind='t10k')\n",
    "    \n",
    "    labels = ['t_shirt_top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n",
    "    Y_str = np.array([labels[j] for j in Y])\n",
    "    \n",
    "    columns = ['X', 'Y', 'Y_str']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    df_tmp = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    df_tmp['X'] = X[:].tolist()\n",
    "    df_tmp['Y'] = Y[:]\n",
    "    df_tmp['Y_str'] = Y_str[:]\n",
    "    \n",
    "    df_tmp.sort_values(['Y'], ascending=[True], inplace=True, axis=0)\n",
    "    labels_ids = df_tmp['Y'].unique()\n",
    "    line_index = 0\n",
    "    \n",
    "    for cur_id in sorted(labels_ids):\n",
    "        # print(\"id: {0}\\tname:{1}\".format(cur_id, labels[cur_id]))\n",
    "        for cur_line in df_tmp[df_tmp['Y'] == cur_id][:100].values:\n",
    "            df.loc[line_index] = [cur_line[i] for i in range(3)]\n",
    "            line_index += 1\n",
    "\n",
    "    # np.savetxt(FLAGS.data_dir + '/Xtest.tsv', X, fmt='%.6e', delimiter='\\t')\n",
    "    # plt.imsave(FLAGS.data_dir + '/mnist-fashion-sprite.png', get_sprite_image(X), cmap='gray')\n",
    "\n",
    "    X = np.array([line for line in df['X'].values])\n",
    "    Y = np.array([line for line in df['Y'].values])\n",
    "    Y_str = np.array([line for line in df['Y_str'].values])\n",
    "\n",
    "    plt.imsave(DATA_DIR + '/mnist-fashion-sprite.png', get_sprite_image(X), cmap='gray')\n",
    "    return X, Y, Y_str, df\n",
    "\n",
    "# Загрузка данных\n",
    "X, Y, Y_str, df = get_data()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_str.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(list(set(Y)))\n",
    "classes_str = sorted(list(set(Y_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Кластерный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_x = np.concatenate((doc2vec, word2vec), axis=1)\n",
    "# cluster_x.shape\n",
    "\n",
    "cluster_x = X\n",
    "cluster_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=len(classes), random_state=0).fit(cluster_x)\n",
    "kmeans_y = kmeans.predict(cluster_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = df.copy()\n",
    "cluster_df[\"kmeans\"] = kmeans_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.5, min_samples=10).fit(cluster_x)\n",
    "labels = db.labels_\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df[\"dbscan\"] = labels\n",
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"cosine\"\n",
    "dist_matrix = pdist(cluster_x, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(dist_matrix, 'ward')\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 30))\n",
    "dn = dendrogram(Z, color_threshold=3, labels=[\"\"]*(Z.shape[0] + 1), distance_sort=\"ascending\", truncate_mode=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.fcluster.html\n",
    "hierarch_1 = fcluster(Z, 2.4, criterion=\"distance\")\n",
    "hierarch_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(hierarch_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarch_2 = fcluster(Z, 45, criterion=\"maxclust\")\n",
    "hierarch_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(hierarch_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df[\"distance\"] = hierarch_1\n",
    "cluster_df[\"maxclust\"] = hierarch_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[cluster_df[cluster_type.value] == cluster_name]\n",
    "print(df.shape)\n",
    "print(cluster_df.shape)\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_name = 'cservice'\n",
    "column_name = 'Y_str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_types = [\"kmeans\", \"dbscan\", \"distance\", \"maxclust\"]\n",
    "\n",
    "def select_cluster_type(cluster_type):\n",
    "    with out:\n",
    "        clear_output()\n",
    "\n",
    "    clusters = sorted(set(cluster_df[cluster_type]))\n",
    "    clusters_list.options = clusters\n",
    "    select_cluster(clusters[0])\n",
    "\n",
    "    \n",
    "def select_cluster(cluster_name):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        \n",
    "        value_counts = df[cluster_df[cluster_type.value] == cluster_name][column_name].value_counts()\n",
    "        summa = sum(value_counts)\n",
    "        \n",
    "        table = []\n",
    "        headers = [\"Наименование категории\", \"Количество\", \"Доля в текущем кластере\", \"Доля от всех заявок данной категории\"]\n",
    "        for elem in value_counts.iteritems():\n",
    "            count = len(df[df[column_name] == elem[0]])\n",
    "            table.append([elem[0], elem[1], \"{0:.3f}%\".format(elem[1] / summa), \"{0:.3f}%\".format(elem[1] / count)])\n",
    "        display(HTML(tabulate.tabulate(table, headers=headers, tablefmt='html')))\n",
    "        \n",
    "\n",
    "cluster_type = widgets.Select(options=cluster_types, description=\"Тип\", rows=10)\n",
    "clusters_list = widgets.Select(options=[], description=\"Кластер\", rows=10)\n",
    "\n",
    "i = widgets.interactive(select_cluster_type, cluster_type=cluster_type)\n",
    "j = widgets.interactive(select_cluster, cluster_name=clusters_list)\n",
    "\n",
    "out = Output()\n",
    "\n",
    "VBox([HBox([i, j]), out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_true = cluster_df[column_name]\n",
    "y_true = le.fit_transform(y_true)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_means\n",
    "dist_squarematrix = squareform(dist_matrix)\n",
    "homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(y_true, kmeans_y)\n",
    "silhouette = silhouette_score(dist_squarematrix, kmeans_y, metric=\"precomputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity, completeness, v_measure, silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcluster, criterion=\"distance\"\n",
    "homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(y_true, hierarch_1)\n",
    "silhouette = silhouette_score(dist_squarematrix, hierarch_1, metric=\"precomputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity, completeness, v_measure, silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcluster, criterion=\"maxclust\"\n",
    "homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(y_true, hierarch_2)\n",
    "silhouette = silhouette_score(dist_squarematrix, hierarch_2, metric=\"precomputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity, completeness, v_measure, silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = [2, 5, 10, 20]\n",
    "X = cluster_x\n",
    "y = y_true\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_t = [1.5, 2, 2.5, 3, 3.5]\n",
    "X = cluster_x\n",
    "y = y_true\n",
    "\n",
    "for t in range_t:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    cluster_labels = fcluster(Z, t, criterion=\"distance\")\n",
    "    n_clusters = len(set(cluster_labels))\n",
    "    \n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
